for (i in 1:nrow(df)) {
set(df,
i,
"Consistency",
sum(as.numeric(df$Trial.result[i:(i + 27 - df$TrialOrderIdx[i])])) +
# Plus the number of lower k choices = 0
ifelse(
df$TrialOrderIdx[i] == 1,
0,
(df$TrialOrderIdx[i] - 1) -
sum(as.numeric(df$Trial.result[(i - (df$TrialOrderIdx[i] - 1)):(i - 1)]))
))
})
# Add a max consistency field
df[, Consistency.max := max(Consistency), by = c("User.code", "Iteration")]
# Calculate the Kest field for each max consistency - based on the geo mean of the max and preceding (within LDR scale!)
df[TrialOrderIdx > 1, Kest := exp(rowMeans(log(cbind(
Kind, shift(Kind, 1, type = "lag")
))))]
df[TrialOrderIdx == 1, Kest := exp(log(Kind))]
#remove all KEST values where consistency is not max (much quicker to calculate them and then remove)
df[Consistency != Consistency.max, Kest := NA]
# Finally make a geomean of all the max consistencies geomeans as their final outcome
dfsums <-
merge(setnames(
dcast(df, User.code + Iteration ~ ., function(x)
c(geomean = exp(mean(log(
x
), na.rm = TRUE))), value.var = 'Kest'),
'.',
'Kest'
),
dfsums,
by = c("User.code", "Iteration"))
#Merge the raw data into the summary
dfsums <-
merge(
dfraw,
dfsums,
by = c("User.code", "Iteration"),
sort = FALSE,
all.x = TRUE
)
return (setDF(dfsums))
}
mydata<-read.csv("D:\\Forever_Ghr\\KIRBY\\KIRBY_TP3.csv", sep=",", header=TRUE)
Block<-c('User.code',	'Iteration',	'Language',	'Completed',	'Completed.Timestamp',	'Processed.Timestamp',	'T1_KIRBY01',	'T1_KIRBY02',	'T1_KIRBY03',	'T1_KIRBY04',	'T1_KIRBY05',	'T1_KIRBY06',	'T1_KIRBY07',	'T1_KIRBY08',	'T1_KIRBY09',	'T1_KIRBY10',	'T1_KIRBY11',	'T1_KIRBY12',	'T1_KIRBY13',	'T1_KIRBY14',	'T1_KIRBY15',	'T1_KIRBY16',	'T1_KIRBY17',	'T1_KIRBY18',	'T1_KIRBY19',	'T1_KIRBY20',	'T1_KIRBY21',	'T1_KIRBY22',	'T1_KIRBY23',	'T1_KIRBY24',	'T1_KIRBY25',	'T1_KIRBY26',	'T1_KIRBY27',	'Kest',	'Kest.NA')
deriveKIRBY(mydata)
#' Derive KIRBY data.
deriveKIRBY <- function(df) {
# if (sanityCheck(df) == FALSE) {
#   stop("df does not meet requirements as passed")
# }
# Remove the flags used in cVEDA
df <-
subset(
df,!grepl("FEEDBACK|js|KIRBY_PCDELAY", Block, ignore.case = TRUE) &
df$Trial.result != 'skip_back'
)
# Some task releases have the block names in lower case...
df$Block[substr(df$Block, 1, 5) == "kirby"] <-
toupper(df$Block[substr(df$Block, 1, 5) == "kirby"])
#Select out the raw data to go in the same file - including the Number of responses var if available ( some digests )
dfraw <- df
if ("Number.of.Responses" %in% colnames(df)) {
dfraw <- dfraw[substr(dfraw$Block, 1, 5) == "KIRBY", ]
dfraw$Trial <- paste(dfraw$Trial, "Nresponses", sep = "_")
dfraw$Trial.result <- dfraw$Number.of.Responses
dfraw <- rbind(df, dfraw)
}
# dfraw <- rotateQuestionnaire(dfraw)
# Remove anything that is not a Kirby block ( id check , ts in the case of imagen)
df <- df[grepl("KIRBY", df$Block), ]
# Select just the LAST response on each question - note that this means repeating a task will update the results - but it also takes the most recent response if they navigate backwards and then change their mind
df <-
df[!duplicated(subset(df, select = c(User.code, Iteration, Trial)), fromLast =
TRUE),]
# if (sanityCheck(
#   df,
#   c(
#     "User.code",
#     "Iteration",
#     "Language",
#     "Completed",
#     "Completed.Timestamp",
#     "Processed.Timestamp",
#     "Trial",
#     "Block",
#     "Trial.result"
#   )
# ) == FALSE) {
#   stop("df does not meet requirements once filtered")
# }
#Convert to DT to speed up the iterative processing
df <- setDT(df)
# Add the computed Kind values
df$Kind[df$Block == 'KIRBY01'] <- 0.000158277936055715
df$Kind[df$Block == 'KIRBY02'] <- 0.00596125186289121
df$Kind[df$Block == 'KIRBY03'] <- 0.00595829195630586
df$Kind[df$Block == 'KIRBY04'] <- 0.248847926267281
df$Kind[df$Block == 'KIRBY05'] <- 0.0413533834586466
df$Kind[df$Block == 'KIRBY06'] <- 0.000398936170212766
df$Kind[df$Block == 'KIRBY07'] <- 0.102564102564103
df$Kind[df$Block == 'KIRBY08'] <- 0.1
df$Kind[df$Block == 'KIRBY09'] <- 0.000158277936055713
df$Kind[df$Block == 'KIRBY10'] <- 0.00604838709677419
df$Kind[df$Block == 'KIRBY11'] <- 0.246753246753247
df$Kind[df$Block == 'KIRBY12'] <- 0.00100338642919854
df$Kind[df$Block == 'KIRBY13'] <- 0.00595829195630586
df$Kind[df$Block == 'KIRBY14'] <- 0.0405643738977072
df$Kind[df$Block == 'KIRBY15'] <- 0.00254817646121994
df$Kind[df$Block == 'KIRBY16'] <- 0.00252235725750975
df$Kind[df$Block == 'KIRBY17'] <- 0.000398089171974522
df$Kind[df$Block == 'KIRBY18'] <- 0.0158045977011494
df$Kind[df$Block == 'KIRBY19'] <- 0.101731601731602
df$Kind[df$Block == 'KIRBY20'] <- 0.000399042298483639
df$Kind[df$Block == 'KIRBY21'] <- 0.0156862745098039
df$Kind[df$Block == 'KIRBY22'] <- 0.0025
df$Kind[df$Block == 'KIRBY23'] <- 0.0414634146341463
df$Kind[df$Block == 'KIRBY24'] <- 0.001001001001001
df$Kind[df$Block == 'KIRBY25'] <- 0.0160493827160494
df$Kind[df$Block == 'KIRBY26'] <- 0.00100267379679144
df$Kind[df$Block == 'KIRBY27'] <- 0.25
# Add the LDR scale
df$LDRscale[df$Block == 'KIRBY01'] <- 2
df$LDRscale[df$Block == 'KIRBY02'] <- 3
df$LDRscale[df$Block == 'KIRBY03'] <- 1
df$LDRscale[df$Block == 'KIRBY04'] <- 3
df$LDRscale[df$Block == 'KIRBY05'] <- 1
df$LDRscale[df$Block == 'KIRBY06'] <- 2
df$LDRscale[df$Block == 'KIRBY07'] <- 1
df$LDRscale[df$Block == 'KIRBY08'] <- 2
df$LDRscale[df$Block == 'KIRBY09'] <- 3
df$LDRscale[df$Block == 'KIRBY10'] <- 2
df$LDRscale[df$Block == 'KIRBY11'] <- 1
df$LDRscale[df$Block == 'KIRBY12'] <- 3
df$LDRscale[df$Block == 'KIRBY13'] <- 1
df$LDRscale[df$Block == 'KIRBY14'] <- 2
df$LDRscale[df$Block == 'KIRBY15'] <- 3
df$LDRscale[df$Block == 'KIRBY16'] <- 2
df$LDRscale[df$Block == 'KIRBY17'] <- 3
df$LDRscale[df$Block == 'KIRBY18'] <- 1
df$LDRscale[df$Block == 'KIRBY19'] <- 3
df$LDRscale[df$Block == 'KIRBY20'] <- 1
df$LDRscale[df$Block == 'KIRBY21'] <- 2
df$LDRscale[df$Block == 'KIRBY22'] <- 1
df$LDRscale[df$Block == 'KIRBY23'] <- 3
df$LDRscale[df$Block == 'KIRBY24'] <- 2
df$LDRscale[df$Block == 'KIRBY25'] <- 3
df$LDRscale[df$Block == 'KIRBY26'] <- 1
df$LDRscale[df$Block == 'KIRBY27'] <- 2
# This analysis only works for completed attempts - remove any early terminations
setorder(df, User.code, Iteration, LDRscale, Kind)
df <- subset(df, df$Completed == "t")
####RECODE refuse to 0 - the calculations will fail otherwise - this is a slight biasing move but hard to see how else to avoid removing them completely?
df$Trial.result[df$Trial.result == 'refuse'] <- 0
## First work out Kest by LDRscale
df[, TrialOrderIdx := seq(.N), by = c("User.code", "Iteration", "LDRscale")]
# Sum of higher and equal k choices which are 1 (LDR)
# TODO refine this with a Non Iterative method - it's not outrageously slow as is though
for (i in 1:nrow(df)) {
set(df,
i,
"Consistency",
sum(as.numeric(df$Trial.result[i:(i + 9 - df$TrialOrderIdx[i])])) +
# Plus the number of lower k choices = 0
ifelse(
df$TrialOrderIdx[i] == 1,
0,
(df$TrialOrderIdx[i] - 1) -
sum(as.numeric(df$Trial.result[(i - (df$TrialOrderIdx[i] - 1)):(i - 1)]))
))
}
# Add a max consistency field
df[, Consistency.max := max(Consistency), by = c("User.code", "Iteration", "LDRscale")]
# Calculate the Kest field for each max consistency - based on the geo mean of the max and preceding (within LDR scale!)
df[TrialOrderIdx > 1, Kest := exp(rowMeans(log(cbind(
Kind, shift(Kind, 1, type = "lag")
))))]
df[TrialOrderIdx == 1, Kest := exp(log(Kind))]
#remove all KEST values where consistency is not max (much quicker to calculate them and then remove)
df[Consistency != Consistency.max, Kest := NA]
# Finally make a geomean of all the max consistencies geomeans as their final outcome
dfsums <-
dcast(df, User.code + Iteration ~ paste('Kest', LDRscale, sep = '.'), function(x)
c(geomean = exp(mean(log(
x
), na.rm = TRUE))), value.var = 'Kest')
## Next overall
# Reset order for overall and remove previous calculation columns
setorder(df, User.code, Iteration, Kind)
df[, c("TrialOrderIdx", "Consistency", "Consistency.max", "Kest") := NULL]
#Create a trial order index
df[, TrialOrderIdx := seq(.N), by = c("User.code", "Iteration")]
system.time(# Sum of higher and equal k choices which are 1 (LDR)
for (i in 1:nrow(df)) {
set(df,
i,
"Consistency",
sum(as.numeric(df$Trial.result[i:(i + 27 - df$TrialOrderIdx[i])])) +
# Plus the number of lower k choices = 0
ifelse(
df$TrialOrderIdx[i] == 1,
0,
(df$TrialOrderIdx[i] - 1) -
sum(as.numeric(df$Trial.result[(i - (df$TrialOrderIdx[i] - 1)):(i - 1)]))
))
})
# Add a max consistency field
df[, Consistency.max := max(Consistency), by = c("User.code", "Iteration")]
# Calculate the Kest field for each max consistency - based on the geo mean of the max and preceding (within LDR scale!)
df[TrialOrderIdx > 1, Kest := exp(rowMeans(log(cbind(
Kind, shift(Kind, 1, type = "lag")
))))]
df[TrialOrderIdx == 1, Kest := exp(log(Kind))]
#remove all KEST values where consistency is not max (much quicker to calculate them and then remove)
df[Consistency != Consistency.max, Kest := NA]
# Finally make a geomean of all the max consistencies geomeans as their final outcome
dfsums <-
merge(setnames(
dcast(df, User.code + Iteration ~ ., function(x)
c(geomean = exp(mean(log(
x
), na.rm = TRUE))), value.var = 'Kest'),
'.',
'Kest'
),
dfsums,
by = c("User.code", "Iteration"))
#Merge the raw data into the summary
dfsums <-
merge(
dfraw,
dfsums,
by = c("User.code", "Iteration"),
sort = FALSE,
all.x = TRUE
)
return (setDF(dfsums))
}
mydata<-read.csv("D:\\Forever_Ghr\\KIRBY\\KIRBY_TP3.csv", sep=",", header=TRUE)
Block<-c('User.code',	'Iteration',	'Language',	'Completed',	'Completed.Timestamp',	'Processed.Timestamp',	'KIRBY01',	'KIRBY02',	'KIRBY03',	'KIRBY04',	'KIRBY05',	'KIRBY06',	'KIRBY07',	'KIRBY08',	'KIRBY09',	'KIRBY10',	'KIRBY11',	'KIRBY12',	'KIRBY13',	'KIRBY14',	'KIRBY15',	'KIRBY16',	'KIRBY17',	'KIRBY18',	'KIRBY19',	'KIRBY20',	'KIRBY21',	'KIRBY22',	'KIRBY23',	'KIRBY24',	'KIRBY25',	'KIRBY26',	'KIRBY27',	'Kest',	'Kest.NA')
deriveKIRBY(mydata)
#' Derive KIRBY data.
deriveKIRBY <- function(df) {
# if (sanityCheck(df) == FALSE) {
#   stop("df does not meet requirements as passed")
# }
# Remove the flags used in cVEDA
df <-
subset(
df,!grepl("FEEDBACK|js|KIRBY_PCDELAY", Block, ignore.case = TRUE) &
df$Trial.result != 'skip_back'
)
# Some task releases have the block names in lower case...
df$Block[substr(df$Block, 1, 5) == "kirby"] <-
toupper(df$Block[substr(df$Block, 1, 5) == "kirby"])
#Select out the raw data to go in the same file - including the Number of responses var if available ( some digests )
dfraw <- df
if ("Number.of.Responses" %in% colnames(df)) {
dfraw <- dfraw[substr(dfraw$Block, 1, 5) == "KIRBY", ]
dfraw$Trial <- paste(dfraw$Trial, "Nresponses", sep = "_")
dfraw$Trial.result <- dfraw$Number.of.Responses
dfraw <- rbind(df, dfraw)
}
# dfraw <- rotateQuestionnaire(dfraw)
# Remove anything that is not a Kirby block ( id check , ts in the case of imagen)
df <- df[grepl("KIRBY", df$Block), ]
# Select just the LAST response on each question - note that this means repeating a task will update the results - but it also takes the most recent response if they navigate backwards and then change their mind
df <-
df[!duplicated(subset(df, select = c(User.code, Iteration, Trial)), fromLast =
TRUE),]
# if (sanityCheck(
#   df,
#   c(
#     "User.code",
#     "Iteration",
#     "Language",
#     "Completed",
#     "Completed.Timestamp",
#     "Processed.Timestamp",
#     "Trial",
#     "Block",
#     "Trial.result"
#   )
# ) == FALSE) {
#   stop("df does not meet requirements once filtered")
# }
#Convert to DT to speed up the iterative processing
df <- setDT(df)
# Add the computed Kind values
df$Kind[df$Block == 'KIRBY01'] <- 0.000158277936055715
df$Kind[df$Block == 'KIRBY02'] <- 0.00596125186289121
df$Kind[df$Block == 'KIRBY03'] <- 0.00595829195630586
df$Kind[df$Block == 'KIRBY04'] <- 0.248847926267281
df$Kind[df$Block == 'KIRBY05'] <- 0.0413533834586466
df$Kind[df$Block == 'KIRBY06'] <- 0.000398936170212766
df$Kind[df$Block == 'KIRBY07'] <- 0.102564102564103
df$Kind[df$Block == 'KIRBY08'] <- 0.1
df$Kind[df$Block == 'KIRBY09'] <- 0.000158277936055713
df$Kind[df$Block == 'KIRBY10'] <- 0.00604838709677419
df$Kind[df$Block == 'KIRBY11'] <- 0.246753246753247
df$Kind[df$Block == 'KIRBY12'] <- 0.00100338642919854
df$Kind[df$Block == 'KIRBY13'] <- 0.00595829195630586
df$Kind[df$Block == 'KIRBY14'] <- 0.0405643738977072
df$Kind[df$Block == 'KIRBY15'] <- 0.00254817646121994
df$Kind[df$Block == 'KIRBY16'] <- 0.00252235725750975
df$Kind[df$Block == 'KIRBY17'] <- 0.000398089171974522
df$Kind[df$Block == 'KIRBY18'] <- 0.0158045977011494
df$Kind[df$Block == 'KIRBY19'] <- 0.101731601731602
df$Kind[df$Block == 'KIRBY20'] <- 0.000399042298483639
df$Kind[df$Block == 'KIRBY21'] <- 0.0156862745098039
df$Kind[df$Block == 'KIRBY22'] <- 0.0025
df$Kind[df$Block == 'KIRBY23'] <- 0.0414634146341463
df$Kind[df$Block == 'KIRBY24'] <- 0.001001001001001
df$Kind[df$Block == 'KIRBY25'] <- 0.0160493827160494
df$Kind[df$Block == 'KIRBY26'] <- 0.00100267379679144
df$Kind[df$Block == 'KIRBY27'] <- 0.25
# Add the LDR scale
df$LDRscale[df$Block == 'KIRBY01'] <- 2
df$LDRscale[df$Block == 'KIRBY02'] <- 3
df$LDRscale[df$Block == 'KIRBY03'] <- 1
df$LDRscale[df$Block == 'KIRBY04'] <- 3
df$LDRscale[df$Block == 'KIRBY05'] <- 1
df$LDRscale[df$Block == 'KIRBY06'] <- 2
df$LDRscale[df$Block == 'KIRBY07'] <- 1
df$LDRscale[df$Block == 'KIRBY08'] <- 2
df$LDRscale[df$Block == 'KIRBY09'] <- 3
df$LDRscale[df$Block == 'KIRBY10'] <- 2
df$LDRscale[df$Block == 'KIRBY11'] <- 1
df$LDRscale[df$Block == 'KIRBY12'] <- 3
df$LDRscale[df$Block == 'KIRBY13'] <- 1
df$LDRscale[df$Block == 'KIRBY14'] <- 2
df$LDRscale[df$Block == 'KIRBY15'] <- 3
df$LDRscale[df$Block == 'KIRBY16'] <- 2
df$LDRscale[df$Block == 'KIRBY17'] <- 3
df$LDRscale[df$Block == 'KIRBY18'] <- 1
df$LDRscale[df$Block == 'KIRBY19'] <- 3
df$LDRscale[df$Block == 'KIRBY20'] <- 1
df$LDRscale[df$Block == 'KIRBY21'] <- 2
df$LDRscale[df$Block == 'KIRBY22'] <- 1
df$LDRscale[df$Block == 'KIRBY23'] <- 3
df$LDRscale[df$Block == 'KIRBY24'] <- 2
df$LDRscale[df$Block == 'KIRBY25'] <- 3
df$LDRscale[df$Block == 'KIRBY26'] <- 1
df$LDRscale[df$Block == 'KIRBY27'] <- 2
# This analysis only works for completed attempts - remove any early terminations
setorder(df, User.code, Iteration, LDRscale, Kind)
df <- subset(df, df$Completed == "t")
####RECODE refuse to 0 - the calculations will fail otherwise - this is a slight biasing move but hard to see how else to avoid removing them completely?
df$Trial.result[df$Trial.result == 'refuse'] <- 0
## First work out Kest by LDRscale
df[, TrialOrderIdx := seq(.N), by = c("User.code", "Iteration", "LDRscale")]
# Sum of higher and equal k choices which are 1 (LDR)
# TODO refine this with a Non Iterative method - it's not outrageously slow as is though
for (i in 1:nrow(df)) {
set(df,
i,
"Consistency",
sum(as.numeric(df$Trial.result[i:(i + 9 - df$TrialOrderIdx[i])])) +
# Plus the number of lower k choices = 0
ifelse(
df$TrialOrderIdx[i] == 1,
0,
(df$TrialOrderIdx[i] - 1) -
sum(as.numeric(df$Trial.result[(i - (df$TrialOrderIdx[i] - 1)):(i - 1)]))
))
}
# Add a max consistency field
df[, Consistency.max := max(Consistency), by = c("User.code", "Iteration", "LDRscale")]
# Calculate the Kest field for each max consistency - based on the geo mean of the max and preceding (within LDR scale!)
df[TrialOrderIdx > 1, Kest := exp(rowMeans(log(cbind(
Kind, shift(Kind, 1, type = "lag")
))))]
df[TrialOrderIdx == 1, Kest := exp(log(Kind))]
#remove all KEST values where consistency is not max (much quicker to calculate them and then remove)
df[Consistency != Consistency.max, Kest := NA]
# Finally make a geomean of all the max consistencies geomeans as their final outcome
dfsums <-
dcast(df, User.code + Iteration ~ paste('Kest', LDRscale, sep = '.'), function(x)
c(geomean = exp(mean(log(
x
), na.rm = TRUE))), value.var = 'Kest')
## Next overall
# Reset order for overall and remove previous calculation columns
setorder(df, User.code, Iteration, Kind)
df[, c("TrialOrderIdx", "Consistency", "Consistency.max", "Kest") := NULL]
#Create a trial order index
df[, TrialOrderIdx := seq(.N), by = c("User.code", "Iteration")]
system.time(# Sum of higher and equal k choices which are 1 (LDR)
for (i in 1:nrow(df)) {
set(df,
i,
"Consistency",
sum(as.numeric(df$Trial.result[i:(i + 27 - df$TrialOrderIdx[i])])) +
# Plus the number of lower k choices = 0
ifelse(
df$TrialOrderIdx[i] == 1,
0,
(df$TrialOrderIdx[i] - 1) -
sum(as.numeric(df$Trial.result[(i - (df$TrialOrderIdx[i] - 1)):(i - 1)]))
))
})
# Add a max consistency field
df[, Consistency.max := max(Consistency), by = c("User.code", "Iteration")]
# Calculate the Kest field for each max consistency - based on the geo mean of the max and preceding (within LDR scale!)
df[TrialOrderIdx > 1, Kest := exp(rowMeans(log(cbind(
Kind, shift(Kind, 1, type = "lag")
))))]
df[TrialOrderIdx == 1, Kest := exp(log(Kind))]
#remove all KEST values where consistency is not max (much quicker to calculate them and then remove)
df[Consistency != Consistency.max, Kest := NA]
# Finally make a geomean of all the max consistencies geomeans as their final outcome
dfsums <-
merge(setnames(
dcast(df, User.code + Iteration ~ ., function(x)
c(geomean = exp(mean(log(
x
), na.rm = TRUE))), value.var = 'Kest'),
'.',
'Kest'
),
dfsums,
by = c("User.code", "Iteration"))
#Merge the raw data into the summary
dfsums <-
merge(
dfraw,
dfsums,
by = c("User.code", "Iteration"),
sort = FALSE,
all.x = TRUE
)
return (setDF(dfsums))
}
mydata<-read.csv("D:\\Forever_Ghr\\KIRBY\\KIRBY_TP3.csv", sep=",", header=TRUE)
Block<-c('User.code',	'Iteration',	'Language',	'Completed',	'Completed.Timestamp',	'Processed.Timestamp',	'KIRBY01',	'KIRBY02',	'KIRBY03',	'KIRBY04',	'KIRBY05',	'KIRBY06',	'KIRBY07',	'KIRBY08',	'KIRBY09',	'KIRBY10',	'KIRBY11',	'KIRBY12',	'KIRBY13',	'KIRBY14',	'KIRBY15',	'KIRBY16',	'KIRBY17',	'KIRBY18',	'KIRBY19',	'KIRBY20',	'KIRBY21',	'KIRBY22',	'KIRBY23',	'KIRBY24',	'KIRBY25',	'KIRBY26',	'KIRBY27',	'Kest',	'Kest.NA')
deriveKIRBY(mydata)
#Designed by Min
#Ver_2020.02.19
rm(list = ls())
library(fdrtool)
name.condition<-c("pump","cashout","explode")
name.colname<-c("Within_Control","Within_Approach","Within_Avoidance","Control_Approach","Control_Avoidance","Approach_Avoidance")
# name.grpname<-c("Adults","Children")
ltp=t1p=t2p<-c(rep(0,length(name.colname)))
for (i in 1:length(name.condition)) {
setwd("D:\\JM_Neo_BART\\TST_Ace_Analyses\\Ace_FDR\\Input\\Net")
mydata<-read.csv(paste(name.condition[i],"_Ace_com.csv", sep="") ,header=TRUE)
for (j in 1:length(name.colname)) {
x<-mydata[,j+1]; a<-mydata[,1]
library(car); library(carData); lt=leveneTest(x~a); ltp[j]<-lt[1,3]
Adults<-mydata[1:80,j+1]; Children<-mydata[81:298,j+1]
tt1=t.test(Adults, Children, paired=FALSE, var.equal=TRUE, conf.level=0.95); t1p[j]<-tt1$p.value
tt2=t.test(Adults,Children,paired=FALSE,var.equal=FALSE,conf.level=0.95); t2p[j]<-tt2$p.value
}
p1=sort(t1p); fdrp1=p.adjust(p1, method="fdr", length(p1)); f1=fdrtool(p1, statistic="pvalue", plot=FALSE)$qval
p2=sort(t2p); fdrp2=p.adjust(p2, method="fdr", length(p2)); f2=fdrtool(p2, statistic="pvalue", plot=FALSE)$qval
res<-cbind(ltp, t1p, t2p, p1, fdrp1, f1, p2, fdrp2, f2)
setwd("D:\\JM_Neo_BART\\TST_Ace_Analyses\\Ace_FDR\\Output\\Net")
write.csv(res,file=paste(name.condition[i],"_Ace_Network_TTest_FDR.csv", sep = ""))
}
#Designed by Shamrockheart
#Ver_2020.02.20
rm(list = ls())
library(car); library(carData); library(fdrtool)
name.condition<-c('pump','cashout','explode')
name.colname<-c('dACC_DLPFC',	'dACC_VMPFC',	'dACC_NAc',	'dACC_Caudate',	'dACC_Putamen',	'dACC_Amygdala',	'dACC_Insula',	'dACC_Hippocampus',	'DLPFC_VMPFC',	'DLPFC_NAc',	'DLPFC_Caudate',	'DLPFC_Putamen',	'DLPFC_Amygdala',	'DLPFC_Insula',	'DLPFC_Hippocampus',	'VMPFC_NAc',	'VMPFC_Caudate',	'VMPFC_Putamen',	'VMPFC_Amygdala',	'VMPFC_Insula',	'VMPFC_Hippocampus',	'NAc_Caudate',	'NAc_Putamen',	'NAc_Amygdala',	'NAc_Insula',	'NAc_Hippocampus',	'Caudate_Putamen',	'Caudate_Amygdala',	'Caudate_Insula',	'Caudate_Hippocampus',	'Putamen_Amygdala',	'Putamen_Insula',	'Putamen_Hippocampus',	'Amygdala_Insula',	'Amygdala_Hippocampus',	'Insula_Hippocampus')
ltp<-c(rep(0,9)); t1p<-c(rep(0,9)); t2p<-c(rep(0,9))
for (i in 1:length(name.condition)) {
setwd("D:\\JM_Neo_BART\\TST_Ace_Analyses\\Ace_FDR\\Input\\PPI36_ROI")
mydata<-read.csv(paste(name.condition[i],"_Ace_PPI_value_int.csv", sep="") ,header=TRUE)
# setwd("D:\\JM_Neo_BART\\JM_Neo_Results\\FDR_Correction_2019\\Input\\PPI_ROI")
# mydata<-read.csv(paste("ave_",name.condition[i],"_NAc_gPPI.csv", sep="") ,header=TRUE)
for (j in 1:length(name.colname)) {
x<-mydata[,j+1]; a<-mydata[,1]
library(car); library(carData); lt=leveneTest(x~a); ltp[j]<-lt[1,3]
Adults<-mydata[1:80,j+1]; Children<-mydata[81:298,j+1]
tt1=t.test(Adults, Children, paired=FALSE, var.equal=TRUE, conf.level=0.95); t1p[j]<-tt1$p.value
tt2=t.test(Adults,Children,paired=FALSE,var.equal=FALSE,conf.level=0.95); t2p[j]<-tt2$p.value
}
p1=sort(t1p); fdrp1=p.adjust(p1, method="fdr", length(p1)); f1=fdrtool(p1, statistic="pvalue", plot=FALSE)$qval
p2=sort(t2p); fdrp2=p.adjust(p2, method="fdr", length(p2)); f2=fdrtool(p2, statistic="pvalue", plot=FALSE)$qval
res<-cbind(ltp, t1p, t2p, p1, fdrp1, f1, p2, fdrp2, f2)
setwd("D:\JM_Neo_BART\TST_Ace_Analyses\Ace_FDR\Output\PPI36_ROI")
write.csv(res,file=paste(name.condition[i],"_Ace_PPI_ROI_TTest_FDR.csv", sep = ""))
}
#Designed by Shamrockheart
#Ver_2020.02.20
rm(list = ls())
library(car); library(carData); library(fdrtool)
name.condition<-c('pump','cashout','explode')
name.colname<-c('dACC_DLPFC',	'dACC_VMPFC',	'dACC_NAc',	'dACC_Caudate',	'dACC_Putamen',	'dACC_Amygdala',	'dACC_Insula',	'dACC_Hippocampus',	'DLPFC_VMPFC',	'DLPFC_NAc',	'DLPFC_Caudate',	'DLPFC_Putamen',	'DLPFC_Amygdala',	'DLPFC_Insula',	'DLPFC_Hippocampus',	'VMPFC_NAc',	'VMPFC_Caudate',	'VMPFC_Putamen',	'VMPFC_Amygdala',	'VMPFC_Insula',	'VMPFC_Hippocampus',	'NAc_Caudate',	'NAc_Putamen',	'NAc_Amygdala',	'NAc_Insula',	'NAc_Hippocampus',	'Caudate_Putamen',	'Caudate_Amygdala',	'Caudate_Insula',	'Caudate_Hippocampus',	'Putamen_Amygdala',	'Putamen_Insula',	'Putamen_Hippocampus',	'Amygdala_Insula',	'Amygdala_Hippocampus',	'Insula_Hippocampus')
ltp<-c(rep(0,9)); t1p<-c(rep(0,9)); t2p<-c(rep(0,9))
for (i in 1:length(name.condition)) {
setwd("D:\\JM_Neo_BART\\TST_Ace_Analyses\\Ace_FDR\\Input\\PPI36_ROI")
mydata<-read.csv(paste(name.condition[i],"_Ace_PPI_value_int.csv", sep="") ,header=TRUE)
# setwd("D:\\JM_Neo_BART\\JM_Neo_Results\\FDR_Correction_2019\\Input\\PPI_ROI")
# mydata<-read.csv(paste("ave_",name.condition[i],"_NAc_gPPI.csv", sep="") ,header=TRUE)
for (j in 1:length(name.colname)) {
x<-mydata[,j+1]; a<-mydata[,1]
library(car); library(carData); lt=leveneTest(x~a); ltp[j]<-lt[1,3]
Adults<-mydata[1:80,j+1]; Children<-mydata[81:298,j+1]
tt1=t.test(Adults, Children, paired=FALSE, var.equal=TRUE, conf.level=0.95); t1p[j]<-tt1$p.value
tt2=t.test(Adults,Children,paired=FALSE,var.equal=FALSE,conf.level=0.95); t2p[j]<-tt2$p.value
}
p1=sort(t1p); fdrp1=p.adjust(p1, method="fdr", length(p1)); f1=fdrtool(p1, statistic="pvalue", plot=FALSE)$qval
p2=sort(t2p); fdrp2=p.adjust(p2, method="fdr", length(p2)); f2=fdrtool(p2, statistic="pvalue", plot=FALSE)$qval
res<-cbind(ltp, t1p, t2p, p1, fdrp1, f1, p2, fdrp2, f2)
setwd("D:\\JM_Neo_BART\\TST_Ace_Analyses\\Ace_FDR\\Output\\PPI36_ROI")
write.csv(res,file=paste(name.condition[i],"_Ace_PPI_ROI_TTest_FDR.csv", sep = ""))
}
